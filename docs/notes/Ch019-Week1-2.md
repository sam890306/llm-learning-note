# Week 1â€“2ï¼ˆç¬¬ä¸€é˜¶æ®µï¼šèƒ½è·‘èµ·æ¥ï¼‰
ç›®æ ‡éå¸¸æ˜ç¡®ï¼š

> âœ… åœ¨ä¸€å° GPU äº‘ä¸»æœºä¸Šï¼Œå¯åŠ¨ä¸€ä¸ªå¯äº¤äº’çš„å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼ˆMistral 7B æˆ– Llama 3 8Bï¼‰
> âœ… èƒ½é€šè¿‡ OpenAI API æ ¼å¼è°ƒç”¨
> âœ… ç†è§£æ˜¾å­˜ã€å»¶è¿Ÿã€ååçš„çœŸå®å«ä¹‰

---

## ğŸš€ Week 1â€“2 æ‰§è¡Œè®¡åˆ’æ€»è§ˆ

| æ¨¡å—     | ç›®æ ‡                          | å·¥å…· / æ¡†æ¶                       |
| ------ | --------------------------- | ----------------------------- |
| ç¯å¢ƒå‡†å¤‡   | æ‹¥æœ‰ä¸€å°èƒ½è¿è¡Œ vLLM çš„ GPU ä¸»æœº       | Vast.ai / RunPod / Paperspace |
| æ¨¡å‹éƒ¨ç½²   | å¯åŠ¨ Mistral-7B-Instruct æ¨ç†æœåŠ¡ | vLLM                          |
| API æ¥å£ | ç”¨ FastAPI æˆ– curl è®¿é—®         | OpenAI-compatible API         |
| ç›‘æ§å­¦ä¹    | æŸ¥çœ‹ GPU åˆ©ç”¨ç‡ã€æ˜¾å­˜ã€åå            | `nvidia-smi`, Grafanaï¼ˆå¯é€‰ï¼‰     |

---

## ğŸ§© Step 1ï¼šç§Ÿä¸€å°åˆé€‚çš„äº‘ä¸»æœº

### ğŸ’» æ¨èé…ç½®ï¼ˆçº¦ $1.2 / å°æ—¶ï¼‰

| ç»„ä»¶  | æœ€ä½è¦æ±‚                         | å»ºè®®           |
| --- | ---------------------------- | ------------ |
| GPU | 1Ã— A100 (40 GB ä»¥ä¸Š) æˆ– 2Ã— L40S | A100 80GB æœ€ä½³ |
| CPU | â‰¥ 8 vCPU                     |              |
| RAM | â‰¥ 64 GB                      |              |
| ç³»ç»Ÿ  | Ubuntu 22.04 LTS             |              |
| å­˜å‚¨  | 100 GB SSD                   |              |

æ¨èå¹³å°ï¼š

* [https://vast.ai](https://vast.ai)
* [https://runpod.io](https://runpod.io)
* [https://lambdalabs.com](https://lambdalabs.com)

> ğŸ“ è‹¥åœ¨ Vast.ai é€‰æœºï¼Œæœç´¢ A100 80GB + Ubuntu 22.04ï¼Œç‚¹å‡»â€œStart Instanceâ€åå³å¯ SSH è¿æ¥ã€‚

---

## âš™ï¸ Step 2ï¼šå®‰è£…åŸºç¡€ç¯å¢ƒ

SSH ç™»å½•åæ‰§è¡Œï¼š

```bash
sudo apt update && sudo apt install -y python3-venv git nvidia-smi
python3 -m venv vllm-env
source vllm-env/bin/activate
pip install --upgrade pip
pip install vllm
```

æµ‹è¯•æ˜¾å¡ï¼š

```bash
nvidia-smi
```

è¾“å‡ºé‡Œåº”èƒ½çœ‹åˆ° A100 æˆ– L40S GPU å’Œ æ˜¾å­˜ä¿¡æ¯ã€‚

---

## ğŸ§  Step 3ï¼šå¯åŠ¨ä¸€ä¸ª vLLM æ¨¡å‹æœåŠ¡

ä¸‹è½½å¹¶è¿è¡Œï¼š

```bash
python -m vllm.entrypoints.openai.api_server \
  --model mistralai/Mistral-7B-Instruct-v0.2 \
  --port 8000 \
  --tensor-parallel-size 1
```

å¦‚æœä½ çš„æœºå™¨æ˜¯ A100 80GB ï¼Œå¯ä»¥ç›´æ¥è·‘ï¼›
è‹¥æ˜¾å­˜å°ï¼ˆ< 40GBï¼‰ï¼Œæ”¹ç”¨ `mistralai/Mistral-7B-v0.1` æˆ– `TheBloke/Mistral-7B-Instruct-v0.2-GPTQ`ï¼ˆé‡åŒ–ç‰ˆï¼‰ã€‚

vLLM ä¼šè‡ªåŠ¨ä» Hugging Face ä¸‹è½½æƒé‡ï¼ˆçº¦ 14 GBï¼‰ï¼Œä¸‹è½½å®Œæ¯•åå¯åŠ¨æœ¬åœ° API æœåŠ¡ã€‚

---

## ğŸ”— Step 4ï¼šæµ‹è¯• OpenAI API å…¼å®¹æ¥å£

å¦å¼€ä¸€ä¸ªç»ˆç«¯ï¼ˆæˆ–åœ¨æœ¬åœ°ï¼‰ï¼Œæ‰§è¡Œï¼š

```bash
curl http://<your_server_ip>:8000/v1/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mistralai/Mistral-7B-Instruct-v0.2",
    "prompt": "Explain why the sky is blue in one paragraph.",
    "max_tokens": 100
  }'
```

è¿”å›åº”ç±»ä¼¼ï¼š

```json
{
  "id": "...",
  "choices": [
    {"text": "The sky appears blue because..."}
  ]
}
```

> ğŸ’¡ è¿™è¯´æ˜ä½ ç°åœ¨æ‹¥æœ‰ä¸€ä¸ªè‡ªéƒ¨ç½²ç‰ˆçš„â€œChatGPT APIâ€ã€‚

---

## ğŸ“Š Step 5ï¼šå­¦ä¹ è§‚å¯Ÿç³»ç»Ÿèµ„æº

1. **GPU æ˜¾å­˜ä¸åˆ©ç”¨ç‡**

   ```bash
   watch -n 1 nvidia-smi
   ```

   ç•™æ„ï¼š

   * æ˜¾å­˜å ç”¨ï¼ˆMemory Usedï¼‰â‰ˆ æ¨¡å‹æƒé‡ + KV-cache + batch
   * GPU Utilization (%) ä»£è¡¨æ¨ç†è´Ÿè½½

2. **æ€§èƒ½æµ‹è¯•ï¼ˆå¯é€‰ï¼‰**

   ```bash
   pip install locust
   ```

   æˆ–ç›´æ¥ç”¨ ab / hey ç­‰å‹æµ‹å·¥å…·ï¼Œè§‚å¯Ÿ RPS ä¸å»¶è¿Ÿå˜åŒ–ã€‚

3. **å¯è§†åŒ–ç›‘æ§ï¼ˆè¿›é˜¶ï¼‰**

   * å®‰è£… Prometheus + Grafana Docker æ ˆæŸ¥çœ‹ GPU metricsã€‚

---

## ğŸ§± Step 6ï¼šæ•´ç†ä½ çš„ç¬¬ä¸€å‘¨å­¦ä¹ æ—¥å¿—

å»ºè®®æ¯å¤©è®°å½•ï¼š

* GPU æ˜¾å­˜éš prompt é•¿åº¦çš„å˜åŒ–
* å“åº”å»¶è¿Ÿéš batch å¤§å°çš„å˜åŒ–
* ä¸åŒæ¨¡å‹ï¼ˆMistralã€Llama 3 ç­‰ï¼‰èµ„æºå¯¹æ¯”

è¿™ä¼šè®©ä½ éå¸¸ç›´è§‚åœ°ç†è§£ã€Œä¸ºä»€ä¹ˆ OpenAI è¦è®¾è®¡ batchingã€KV-cacheã€åˆ†å¸ƒå¼æ¨ç†ã€è¿™äº›å·¥ç¨‹é€»è¾‘ã€‚

---

## ğŸªœ Step 7ï¼ˆå¯é€‰ï¼‰ï¼šæ·»åŠ ä¸€ä¸ªå‰ç«¯ç•Œé¢

```bash
pip install gradio
```

```python
import gradio as gr
from openai import OpenAI
client = OpenAI(base_url="http://localhost:8000/v1", api_key="none")

def chat(prompt):
    r = client.completions.create(model="mistralai/Mistral-7B-Instruct-v0.2",
                                  prompt=prompt, max_tokens=200)
    return r.choices[0].text

gr.Interface(fn=chat, inputs="text", outputs="text").launch()
```

> ç°åœ¨ä½ å°±æœ‰äº†ä¸€ä¸ªâ€œè‡ªå·±æ‰˜ç®¡çš„ ChatGPT ç½‘é¡µâ€ã€‚

---

## âœ… Week 1â€“2 æˆæœæ£€æŸ¥è¡¨

| èƒ½åŠ›             | æ£€æŸ¥æ–¹å¼                     |
| -------------- | ------------------------ |
| âœ… èƒ½ç™»å½• GPU ä¸»æœº   | `nvidia-smi` èƒ½çœ‹åˆ° A100    |
| âœ… èƒ½è¿è¡Œ vLLM API | `curl` è¿”å›æ­£å¸¸ç»“æœ            |
| âœ… èƒ½è§‚æµ‹æ˜¾å­˜        | æ˜¾å­˜éš prompt å˜åŒ–            |
| âœ… ç†è§£åŸºç¡€ç»“æ„       | çŸ¥é“ä»€ä¹ˆæ˜¯æ¨¡å‹æƒé‡ã€tokenã€KV cache |
| âœ… å¯äº¤äº’ç½‘é¡µï¼ˆå¯é€‰ï¼‰    | Gradio ç•Œé¢å¯ç”¨              |

---
